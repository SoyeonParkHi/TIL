> 도서 <누구나 자료구조와 알고리즘> 제이 웬그로우

### 1. 자료 구조가 중요한 까닭
* 프로그래밍은 데이터를 다루고, 데이터 조직이 코드의 실행 속도에 미치는 영향이 크다.
* 연산 : 대부분의 자료 구조가 사용하는 네 가지 기본 방법
    - 읽기 : 자료 구조 내 특정 위치 찾아보는 것
        + 배열과 집합에서 컴퓨터가 가야할 메모리 주소를 알고 있으므로 한 단계 연산 수행
    - 검색 : 자료 구조 내에서 특정 값을 찾는 것
        + 배열과 집합에서 최대 n 단계 수행 (선형 검색의 경우) 
    - 삽입 : 자료 구조에 새로운 값을 추가
        + 배열에서 삽입 위치보다 뒤의 원소를 이동해야 하므로, 최대 n+1 단계 수행 (1은 삽입 연산 의미)
        + 집합은 중복을 허용하지 않으므로 삽입 전에 검색 먼저 수행하여 최대 2n+1 단계 수행
    - 삭제 : 자료 구조에서 값을 제거
        + 배열과 집합에서 검색과 마찬가지로, 삭제 위치보다 뒤의 원소를 당겨야 하므로 최대 n단계 수행

### 2. 알고리즘이 중요한 까닭
* 정렬된 배열은 삽입에 있어 일반 배열보다 덜 효율적이지만, 검색 연산에서는 더 효율적이다.
    - 선형검색 구현 :  
    ```python
    def linear_search(array, value):
        for i in range(len(array)):
            if value == array[i]:
                return i
            return None
    ```
* 선형 검색의 경우 값이 배열에 없을 때 검색을 더 빨리 멈출 수 있다.
* 이진 검색(binary search) : 정렬된 배열에서 중간값 검색을 반복
    - 이진 검색 구현 :  
    ```python
    def binary_search(array, value) :
        lower_bound = 0
        upper_bound = array[-1]

        while lower_bound <= upper_bound :
            midpoint = (upper_bound + lower_bound) / 2
            if value < array[midpoint] :
                upper_bound = midpoint - 1
            elif value > array[midpoint] :
                lower_bound = midpoint + 1
            else : 
                return midpoint
        return None
    ```
    - 선형 검색은 원소 수만큼의 단계가 필요하지만, 이진 검색에서는 배열의 원소 수를 두 배로 늘릴 때마다 한 단계만 늘어난다.
    - 배열이 커질수록 성능 차이가 심해진다.
* 즉, 정렬된 배열은 삽입은 일반 배열보다 느리지만 검색은 훨씬 빠르다.

### 3. 빅 오 표기법
* 시간 복잡도를 일관된 언어로 설명하기 위해 수학적 개념을 차용해 형식화한 표현 (= 단계 수 계산)
* $O(1)$ : 데이터 크기에 상관 없이 알고리즘에 필요한 단계 수가 일정 (상수 시간)
    - 배열 읽기, 배열 끝의 삽입과 삭제
* $O(N)$ : 배열 내에 N개의 원소가 있을 때 알고리즘을 수행하는데 N개의 단계가 필요 (선형 시간)
    - 선형 검색
* 빅 오 표기법은 알고리즘에 얼마나 많은 단계가 필요한지를 알고리즘이 처리할 데이터 원소 수에 따라 설명한다. 즉, **데이터가 증가할수록 단계 수는 어떻게 변하는가?** 라는 질문에 답을 한다.
    - 많은 단계가 걸리는 $O(1)$도 일정 시점에 다다르면 $O(N)$보다 효율적인 지점에 다다르므로 $O(1)$이 $O(N)$보다 효율적이다.
* 일반적으로 빅 오 표기법은 최악의 시나리오를 의미한다. 비관적인 접근이 유용한 도구일 수 있기 때문
* $O(\log N)$ : 데이터가 2배로 증가할 때마다 한 단계씩 늘어나는 알고리즘 (로그 시간)
    - 이진 검색
    - $O(N)$보다 효율적이지만 $O(1)$보다 비효율적이다. (데이터의 증가에 따른 단계의 증가로 비교)

### 4. 빅 오로 코드 속도 올리기
* 버블 정렬(bubble sort) : 배열의 처음부터 더이상 교환하지 않을때까지 패스스루(두 항목을 원소의 크기에 따라 순서를 교환하는 것) 반복
    - 버블 정렬 구현 :  
    ```python
    def bubble_sort(array) : 
        unsorted_until_index = len(array) - 1
        sorted = False

        while not sorted :
            sorted = True
            for i in range(unsorted_until_index) :
                if array[i] > array[i + 1] :
                    sorted = False
                    array[i], array[i + 1] = array[i + 1], array[i]
            unsorted_until_index = unsorted_until_index - 1
    ```
    - 버블 정렬 알고리즘에 포함된 단계는 비교와 교환 두 종류다.
    - 배열이 내림차순으로 정렬된 최악의 시나리오라면 $N$이 증가할때마다 대략 $N^2$만큼 단계가 늘어난다.
* $O(N^2)$ : 이차 시간 - 데이터가 증가할 때 단계 수가 급격히 늘어나므로 비효율적
    - 중첩 루프

### 5. 빅 오를 사용하거나 사용하지 않는 코드 최적화
* 빅 오 표기법에서 효율성이 같아 보이는 두 알고리즘을 구별하는 방법
* 선택 정렬(selection sort) : 배열의 처음부터 끝까지 최소값 결정 후 최소값의 인덱스와 패스스루 시작점의 인덱스 교환 (정렬될때까지 반복)
    - 선택 정렬 구현 :  
    ```python
    def selection_sort(array) :
        for i in range(len(array)) :
            lowest_number_index = i
            for j in range(i + 1, len(array)) :
                if array[j] < array[lowest_number_index] :
                    lowest_number_index = j
                if lowest_number_index != i :
                    temp = array[i]
                    array[i] = array[lowest_number_index]
                    array[lowest_number_index] = temp
    ```
    - 선택 정렬은 버블 정렬보다 최악의 시나리오에서 단계 수가 반 정도 적다.
    - 하지만 빅 오 표기법은 **상수를 무시**한다.
    - $O(N^2)$으로 동일
* 빅 오는 특정 시점부터 어떤 유형이 다른 유형보다 속도가 빨라지고 이후로도 계속해서 더 빠른 경우 두 유형을 다르게 분류하고자 한다.(그 시점은 중요하지 X)
    - 같은 분류에 속하는 알고리즘을 비교하기 위해서는 분석이 더 필요(상수 비교)

### 6. 긍정적인 시나리오 최적화
* 최악의 알고리즘이 아닌 모든 시나리오를 고려할 가치가 있는 상황
* 삽입 정렬(insersion sort) : 첫 번째 패스스루에서 임시로 1(두 번째 셀)의 값을 삭제하고 이 값을 임시 변수에 저장한다. 공백 왼쪽에 있는 값과 비교해 더 크면 오른쪽으로 시프트한다. 임시로 삭제한 값보다 작은 값을 만나거나 배열의 왼쪽 끝에 도달해야 시프트 단계가 끝난다. 시프트 단계가 끝나면 임시로 제거한 값을 현재 공백에 삽입하고 배열이 정렬될 때까지 이를 반복한다.
    - 삽입 정렬 구현 :  
    ```python
    def insertion_sort(array) :
        for index in range(1, len(array)) :
            position = index
            temp_value = array[index]

            while position > 0 and array[position - 1] > temp_value :
                array[position] = array[position - 1]
                position -= 1

            array[position] = temp_value
    ```
    - 최악의 시나리오에서, 삽입정렬은 $N^2/2$번의 비교, $N^2/2$번의 시프트, $N-1$번의 삭제와 $N-1$번의 삽입이 일어나므로 총 $N^2 + 2N - 2$단계가 걸린다.
* 빅 오 표기법은 가장 높은 차수의 N만 고려한다
    - N이 증가할수록 낮은 차원의 N의 계수보다 가장 높은 차수의 $N^x$의 영향이 훨씬 커지기 때문
    - 따라서 삽입 정렬은 $O(N^2)$이다. 하지만 버블 정렬($N^2$ 단계), 선택정렬($N^2 / 2$ 단계)보다 느리다고 할 수 있다.
* 가장 자주 일어나는 경우는 최악의 시나리오보다 평균 시나리오라고 할 수 있다.
    - 삽입 정렬의 경우 최선의 시나리오에서는 약 N단계가 걸린다. 즉, 시나리오에 따라 성능이 크게 좌우된다.  
    반면, 선택 정렬에는 어떤 시점에 미리 패스스루를 끝낼 메커니즘이 없으므로 최선의 시나리오에서도 $N^2/2$단계가 걸린다.
    - 선택 정렬과 삽입 정렬을 비교할 때, 평균적으로 두 정렬은 유사하게 수행된다. 다루는 데이터의 정렬의 정도를 예측할 수 있을 때, 삽입 정렬이나 선택 정렬이 더 빠를 것도 예상할 수 있다.

    ### 7. 해시 테이블로 매우 빠른 룩업

    ### 8. 스택과 큐로 간결한 코드 생성

    ### 9. 재귀를 사용한 재귀적 반복

    ### 10. 속도를 높이는 재귀 알고리즘

    ### 11. 노드 기반 자료 구조

    ### 12. 이진 트리로 속도 향상

    ### 13. 그래프로 뭐든지 연결하기

    ### 14. 공간 제약 다루기